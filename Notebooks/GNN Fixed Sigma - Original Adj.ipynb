{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import load_data,normalize,toy_data,norm_embed,nmi_score\n",
    "\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from layers import GraphConvolution, InnerProduct\n",
    "from utils import norm_embed\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, batch_size, nfeat, nhid, ndim, mu0, sigma0):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        self.gc1 = GraphConvolution(batch_size, nfeat, nhid, mu0, sigma0, scale=False)\n",
    "        self.embeddings = GraphConvolution(batch_size, nhid, 2*ndim, mu0, sigma0, scale=True)\n",
    "        self.reconstructions = InnerProduct(2*ndim)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = self.embeddings(x, adj)\n",
    "        x = norm_embed(x)\n",
    "        mu = F.relu(self.reconstructions(x))\n",
    "        return mu\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "torch.set_printoptions(sci_mode=False,precision=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='Disables CUDA training.')\n",
    "parser.add_argument('--fastmode', action='store_true', default=False,\n",
    "                    help='Validate during training pass.')\n",
    "parser.add_argument('--seed', type=int, default=426, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=10000,\n",
    "                    help='Number of epochs to train.')\n",
    "parser.add_argument('--lr', type=float, default=0.001,\n",
    "                    help='Initial learning rate.')\n",
    "parser.add_argument('--weight_decay', type=float, default=10e-8,\n",
    "                    help='Weight decay (L2 loss on parameters).')\n",
    "parser.add_argument('--hidden', type=int, default=16,\n",
    "                    help='Number of hidden units.')\n",
    "parser.add_argument('--ndim', type=int, default=2,\n",
    "                    help='Embeddings dimension.')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    # Taxi Dataset Graph\n",
    "    adj = load_data()\n",
    "    #adj = load_data(daily=True)\n",
    "else:\n",
    "    #Toy Example Graph\n",
    "    adj = toy_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GraphNeuralNet(adj,dim):\n",
    "    \n",
    "    # Set the random seed\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.cuda:\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "        \n",
    "    args.ndim = dim\n",
    "    \n",
    "    adj_norm = normalize(adj)\n",
    "\n",
    "    adj = torch.FloatTensor(np.array(adj))\n",
    "    \n",
    "    # loss function\n",
    "    criterion = torch.nn.GaussianNLLLoss()\n",
    "\n",
    "    # Model and optimizer\n",
    "    model = GNN(batch_size=adj_norm.shape[0],\n",
    "                nfeat=adj_norm.shape[1],\n",
    "                nhid=args.hidden,\n",
    "                ndim=args.ndim,\n",
    "                mu0=adj.mean(),\n",
    "                sigma0=adj.std())\n",
    "\n",
    "    activation = {}\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    model.embeddings.register_forward_hook(get_activation('embeddings'))\n",
    "    \n",
    "\n",
    "    features = torch.FloatTensor(torch.eye(adj.shape[1]))\n",
    "    features = features.reshape((1,adj.shape[1],adj.shape[1]))\n",
    "    features = features.repeat(adj.shape[0], 1, 1)\n",
    "\n",
    "    if args.cuda:\n",
    "        model.cuda()\n",
    "        features = features.cuda()\n",
    "        adj = adj.cuda()\n",
    "        adj_norm = adj_norm.cuda()\n",
    "\n",
    "\n",
    "    # Train model\n",
    "    t_total = time.time()\n",
    "    \n",
    "    # NULL Model\n",
    "    mu0 = adj.mean()*torch.ones(adj.shape[1:])\n",
    "    sigma0 = adj.std()*torch.ones(adj.shape[1:])\n",
    "    with torch.no_grad():\n",
    "        loss0 = criterion(torch.flatten(adj), torch.flatten(mu0), torch.flatten(torch.square(sigma0)))\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "\n",
    "        t = time.time()\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        mu = model(features, adj_norm)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            mse = torch.nn.MSELoss()\n",
    "            mseloss = mse(torch.flatten(mu),torch.flatten(adj_norm))\n",
    "            sig = torch.sqrt(mseloss)\n",
    "        sigma = sig * torch.ones(adj_norm.shape,requires_grad=True)\n",
    "        \n",
    "        loss = criterion(torch.flatten(adj), torch.flatten(mu), torch.flatten(torch.square(sigma))) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 0:\n",
    "            best_loss = loss\n",
    "        else:\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            print('Epoch: {:04d}'.format(epoch + 1),\n",
    "                  'loss: {:.8f}'.format(best_loss.item()),\n",
    "                  'time: {:.4f}s'.format(time.time() - t))\n",
    "            \n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "    \n",
    "    return adj,mu,best_loss.item(),loss0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss: 3721641.25000000 time: 0.0040s\n",
      "Epoch: 1001 loss: 27.80582047 time: 0.0040s\n",
      "Epoch: 2001 loss: 15.72799015 time: 0.0040s\n",
      "Epoch: 3001 loss: 12.97514057 time: 0.0000s\n",
      "Epoch: 4001 loss: 11.97752094 time: 0.0000s\n",
      "Epoch: 5001 loss: 11.53821468 time: 0.0010s\n",
      "Epoch: 6001 loss: 11.31738186 time: 0.0020s\n",
      "Epoch: 7001 loss: 11.19578457 time: 0.0010s\n",
      "Epoch: 8001 loss: 11.12407303 time: 0.0010s\n",
      "Epoch: 9001 loss: 11.08464336 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 18.5210s\n",
      "Epoch: 0001 loss: 930052.00000000 time: 0.0020s\n",
      "Epoch: 1001 loss: 14.97016239 time: 0.0010s\n",
      "Epoch: 2001 loss: 12.10234642 time: 0.0010s\n",
      "Epoch: 3001 loss: 11.48444462 time: 0.0020s\n",
      "Epoch: 4001 loss: 11.25874901 time: 0.0020s\n",
      "Epoch: 5001 loss: 11.15270519 time: 0.0020s\n",
      "Epoch: 6001 loss: 11.09746170 time: 0.0020s\n",
      "Epoch: 7001 loss: 11.06853104 time: 0.0020s\n",
      "Epoch: 8001 loss: 11.05021191 time: 0.0010s\n",
      "Epoch: 9001 loss: 11.03701973 time: 0.0000s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 19.6863s\n",
      "Epoch: 0001 loss: 413246.18750000 time: 0.0030s\n",
      "Epoch: 1001 loss: 12.69277191 time: 0.0000s\n",
      "Epoch: 2001 loss: 11.49156189 time: 0.0030s\n",
      "Epoch: 3001 loss: 11.23010921 time: 0.0030s\n",
      "Epoch: 4001 loss: 11.12856579 time: 0.0040s\n",
      "Epoch: 5001 loss: 11.08241558 time: 0.0040s\n",
      "Epoch: 6001 loss: 11.05814362 time: 0.0000s\n",
      "Epoch: 7001 loss: 11.04252052 time: 0.0030s\n",
      "Epoch: 8001 loss: 11.03069973 time: 0.0030s\n",
      "Epoch: 9001 loss: 11.02100277 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 19.9450s\n",
      "Epoch: 0001 loss: 232396.31250000 time: 0.0030s\n",
      "Epoch: 1001 loss: 11.93795109 time: 0.0000s\n",
      "Epoch: 2001 loss: 11.28852749 time: 0.0000s\n",
      "Epoch: 3001 loss: 11.14025116 time: 0.0000s\n",
      "Epoch: 4001 loss: 11.08418465 time: 0.0040s\n",
      "Epoch: 5001 loss: 11.05755997 time: 0.0040s\n",
      "Epoch: 6001 loss: 11.04152298 time: 0.0020s\n",
      "Epoch: 7001 loss: 11.02963734 time: 0.0000s\n",
      "Epoch: 8001 loss: 11.01980972 time: 0.0040s\n",
      "Epoch: 9001 loss: 11.01186180 time: 0.0000s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 20.4632s\n",
      "Epoch: 0001 loss: 148700.92187500 time: 0.0000s\n",
      "Epoch: 1001 loss: 11.60187721 time: 0.0000s\n",
      "Epoch: 2001 loss: 11.19526196 time: 0.0030s\n",
      "Epoch: 3001 loss: 11.09930611 time: 0.0000s\n",
      "Epoch: 4001 loss: 11.06319714 time: 0.0000s\n",
      "Epoch: 5001 loss: 11.04438972 time: 0.0000s\n",
      "Epoch: 6001 loss: 11.03143120 time: 0.0020s\n",
      "Epoch: 7001 loss: 11.02107525 time: 0.0020s\n",
      "Epoch: 8001 loss: 11.01274681 time: 0.0020s\n",
      "Epoch: 9001 loss: 11.00668430 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 20.3838s\n",
      "Epoch: 0001 loss: 103242.78906250 time: 0.0020s\n",
      "Epoch: 1001 loss: 11.42509460 time: 0.0020s\n",
      "Epoch: 2001 loss: 11.14360523 time: 0.0020s\n",
      "Epoch: 3001 loss: 11.07736397 time: 0.0030s\n",
      "Epoch: 4001 loss: 11.05082607 time: 0.0000s\n",
      "Epoch: 5001 loss: 11.03556442 time: 0.0000s\n",
      "Epoch: 6001 loss: 11.02414131 time: 0.0030s\n",
      "Epoch: 7001 loss: 11.01492500 time: 0.0030s\n",
      "Epoch: 8001 loss: 11.00809574 time: 0.0000s\n",
      "Epoch: 9001 loss: 11.00374794 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 20.6661s\n",
      "Epoch: 0001 loss: 75836.39843750 time: 0.0020s\n",
      "Epoch: 1001 loss: 11.32309818 time: 0.0030s\n",
      "Epoch: 2001 loss: 11.11266327 time: 0.0030s\n",
      "Epoch: 3001 loss: 11.06328011 time: 0.0020s\n",
      "Epoch: 4001 loss: 11.04246140 time: 0.0020s\n",
      "Epoch: 5001 loss: 11.02902317 time: 0.0020s\n",
      "Epoch: 6001 loss: 11.01845932 time: 0.0020s\n",
      "Epoch: 7001 loss: 11.01055717 time: 0.0030s\n",
      "Epoch: 8001 loss: 11.00525665 time: 0.0000s\n",
      "Epoch: 9001 loss: 11.00163269 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 20.7991s\n",
      "Epoch: 0001 loss: 58050.73437500 time: 0.0040s\n",
      "Epoch: 1001 loss: 11.25533867 time: 0.0000s\n",
      "Epoch: 2001 loss: 11.09273911 time: 0.0000s\n",
      "Epoch: 3001 loss: 11.05379295 time: 0.0040s\n",
      "Epoch: 4001 loss: 11.03604698 time: 0.0040s\n",
      "Epoch: 5001 loss: 11.02361488 time: 0.0040s\n",
      "Epoch: 6001 loss: 11.01416016 time: 0.0040s\n",
      "Epoch: 7001 loss: 11.00744057 time: 0.0000s\n",
      "Epoch: 8001 loss: 11.00323009 time: 0.0000s\n",
      "Epoch: 9001 loss: 11.00010014 time: 0.0000s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 20.7026s\n",
      "Epoch: 0001 loss: 45858.40234375 time: 0.0000s\n",
      "Epoch: 1001 loss: 11.20879745 time: 0.0040s\n",
      "Epoch: 2001 loss: 11.07873440 time: 0.0040s\n",
      "Epoch: 3001 loss: 11.04693508 time: 0.0021s\n",
      "Epoch: 4001 loss: 11.03090191 time: 0.0022s\n",
      "Epoch: 5001 loss: 11.01918983 time: 0.0000s\n",
      "Epoch: 6001 loss: 11.01082611 time: 0.0000s\n",
      "Epoch: 7001 loss: 11.00533104 time: 0.0000s\n",
      "Epoch: 8001 loss: 11.00165558 time: 0.0000s\n",
      "Epoch: 9001 loss: 10.99897194 time: 0.0040s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.2348s\n",
      "Epoch: 0001 loss: 37138.32421875 time: 0.0040s\n",
      "Epoch: 1001 loss: 11.17502117 time: 0.0000s\n",
      "Epoch: 2001 loss: 11.06832886 time: 0.0000s\n",
      "Epoch: 3001 loss: 11.04139042 time: 0.0040s\n",
      "Epoch: 4001 loss: 11.02646542 time: 0.0030s\n",
      "Epoch: 5001 loss: 11.01567078 time: 0.0030s\n",
      "Epoch: 6001 loss: 11.00825596 time: 0.0000s\n",
      "Epoch: 7001 loss: 11.00370026 time: 0.0020s\n",
      "Epoch: 8001 loss: 11.00041771 time: 0.0030s\n",
      "Epoch: 9001 loss: 10.99812508 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.2451s\n",
      "Epoch: 0001 loss: 30687.19140625 time: 0.0020s\n",
      "Epoch: 1001 loss: 11.14997482 time: 0.0040s\n",
      "Epoch: 2001 loss: 11.06040573 time: 0.0000s\n",
      "Epoch: 3001 loss: 11.03688812 time: 0.0040s\n",
      "Epoch: 4001 loss: 11.02262592 time: 0.0022s\n",
      "Epoch: 5001 loss: 11.01280022 time: 0.0000s\n",
      "Epoch: 6001 loss: 11.00637054 time: 0.0000s\n",
      "Epoch: 7001 loss: 11.00238514 time: 0.0040s\n",
      "Epoch: 8001 loss: 10.99944115 time: 0.0000s\n",
      "Epoch: 9001 loss: 10.99744892 time: 0.0000s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.5156s\n",
      "Epoch: 0001 loss: 25781.14843750 time: 0.0039s\n",
      "Epoch: 1001 loss: 11.13088799 time: 0.0000s\n",
      "Epoch: 2001 loss: 11.05453873 time: 0.0043s\n",
      "Epoch: 3001 loss: 11.03293705 time: 0.0040s\n",
      "Epoch: 4001 loss: 11.01933193 time: 0.0040s\n",
      "Epoch: 5001 loss: 11.01038742 time: 0.0000s\n",
      "Epoch: 6001 loss: 11.00490856 time: 0.0040s\n",
      "Epoch: 7001 loss: 11.00127506 time: 0.0040s\n",
      "Epoch: 8001 loss: 10.99866486 time: 0.0040s\n",
      "Epoch: 9001 loss: 10.99685097 time: 0.0040s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 22.9369s\n",
      "Epoch: 0001 loss: 21963.53125000 time: 0.0040s\n",
      "Epoch: 1001 loss: 11.11581612 time: 0.0040s\n",
      "Epoch: 2001 loss: 11.04962635 time: 0.0000s\n",
      "Epoch: 3001 loss: 11.02938938 time: 0.0000s\n",
      "Epoch: 4001 loss: 11.01656818 time: 0.0040s\n",
      "Epoch: 5001 loss: 11.00846004 time: 0.0040s\n",
      "Epoch: 6001 loss: 11.00369835 time: 0.0000s\n",
      "Epoch: 7001 loss: 11.00034142 time: 0.0060s\n",
      "Epoch: 8001 loss: 10.99802971 time: 0.0024s\n",
      "Epoch: 9001 loss: 10.99630451 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.8668s\n",
      "Epoch: 0001 loss: 18934.71484375 time: 0.0030s\n",
      "Epoch: 1001 loss: 11.10363579 time: 0.0000s\n",
      "Epoch: 2001 loss: 11.04542255 time: 0.0030s\n",
      "Epoch: 3001 loss: 11.02622986 time: 0.0040s\n",
      "Epoch: 4001 loss: 11.01423073 time: 0.0000s\n",
      "Epoch: 5001 loss: 11.00694084 time: 0.0040s\n",
      "Epoch: 6001 loss: 11.00266647 time: 0.0000s\n",
      "Epoch: 7001 loss: 10.99956989 time: 0.0040s\n",
      "Epoch: 8001 loss: 10.99749374 time: 0.0021s\n",
      "Epoch: 9001 loss: 10.99578476 time: 0.0040s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 21.9554s\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "nmi = []\n",
    "dims = [x for x in range(1,15)]\n",
    "for dim in dims:\n",
    "    adj_norm,mu,loss,loss0 = GraphNeuralNet(adj=adj,dim=dim)\n",
    "    losses.append(loss)\n",
    "    nmi.append(nmi_score(adj_norm[0],mu.reshape(adj_norm.shape[1:]).detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI Score dim 1 = 0.3915337489396262\n",
      "NMI Score dim 2 = 0.3811469344873496\n",
      "NMI Score dim 3 = 0.3634165979001762\n",
      "NMI Score dim 4 = 0.3530907494868377\n",
      "NMI Score dim 5 = 0.3454410717425722\n",
      "NMI Score dim 6 = 0.34544107174257227\n",
      "NMI Score dim 7 = 0.3454410717425722\n",
      "NMI Score dim 8 = 0.34544107174257216\n",
      "NMI Score dim 9 = 0.3454410717425722\n",
      "NMI Score dim 10 = 0.3463667574912783\n",
      "NMI Score dim 11 = 0.3454410717425722\n",
      "NMI Score dim 12 = 0.34544107174257216\n",
      "NMI Score dim 13 = 0.3443386358612565\n",
      "NMI Score dim 14 = 0.3623629763653564\n",
      "\n",
      " NLL0 = 11.34196949005127\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAjeUlEQVR4nO3de3zedX338dcnV85pDlfa9JA2hwKl0GItScQVEQ84LQypoji6TdHhjXNy69zmhvd2e5jb1Ln7dk6YDl0te8hAhiAohU6F24rgJC0tpE1PQA/pMW3aJM358Ln/uH4tacnpSq8rvytX3s/HI49cv+/1+115l0fLO7/T92fujoiIyHhlhB1ARESmFhWHiIjERcUhIiJxUXGIiEhcVBwiIhKXzLADTIZZs2Z5dXV12DFERKaUjRs3HnP3snPHp0VxVFdXU19fH3YMEZEpxcz2DjeuQ1UiIhIXFYeIiMRFxSEiInFRcYiISFxUHCIiEhcVh4iIxEXFISIicVFxjOKRzQf4/q+HvYxZRGTaUnGM4omGw/zrhpfCjiEiklJUHKOorYqyv6WLo23dYUcREUkZKo5R1FRFAdi490TISUREUkfSisPM1pjZUTNrGDJ2k5ltNbNBM6sbZduVZrbDzHab2R1Dxs3M/s7MdppZo5l9Mln5AZaWF5GdmaHiEBEZIpl7HGuBleeMNQA3AhtG2sjMIsBdwLXAEmC1mS0J3v4wUAFc4u6XAvcnNvLZcjIjLJtfzMZ9Kg4RkdOSVhzuvgFoOWes0d13jLHpFcBud3/Z3XuJlcOq4L2PA3/j7oPB5x1NcOzXqK2O0nCgle6+gWT/KBGRKSEVz3HMB/YPWW4KxgAuBH7XzOrN7HEzWzTSh5jZbcF69c3NzRMOU1sZpW/AaTjQOuHPEBFJJ6lYHKPJAbrdvQ74DrBmpBXd/W53r3P3urKy1zyHZNx0glxE5GypWBwHiJ3HOG1BMAaxvY+HgtcPA8uSHWbWjByqZ+arOEREAqlYHM8Bi8xsoZllAzcDjwbv/Qh4W/D6LcDOyQhUUxVl074TuPtk/DgRkZSWzMtx7wOeBRabWZOZ3Wpm7zWzJmAF8JiZrQ/WLTezdQDu3g/cDqwHGoEH3H1r8LFfAd5nZi8CXwY+mqz8Q9VWRTl2qpd9LZ2T8eNERFJa0p457u6rR3jr4WHWPQhcN2R5HbBumPVOAr+ToIjjVjvkPEfVzILJ/vEiIiklFQ9VpZxFswspzMnUeQ4REVQc4xLJMJZXlqg4RERQcYxbbVWUHUfaaevuCzuKiEioVBzjVFsVxR027zsZdhQRkVCpOMZpeUUJGaYbAUVEVBzjVJibxeK5RWzShIciMs2pOOJQW1XC8/tOMjCoGwFFZPpSccShtirKqZ5+dh5pDzuKiEhoVBxxqK0sBXSeQ0SmNxVHHCpK85g1I4dNKg4RmcZUHHEwM2qrSvREQBGZ1lQccaqtirL3eCfN7T1hRxERCYWKI061erCTiExzKo44LS0vJjuSofs5RGTaUnHEKTcrwmXzi7THISLTlopjAmqrorzY1EpP/0DYUUREJp2KYwJqq0rpHRik4UBb2FFERCadimMCaqpKAHQ/h4hMSyqOCZhdmEtlab7Oc4jItKTimKDaqigb953AXRMeisj0krTiMLM1ZnbUzBqGjN1kZlvNbNDM6kbZdqWZ7TCz3WZ2x5DxtWb2ipltDr6WJyv/WGqqojS399B0oiusCCIioUjmHsdaYOU5Yw3AjcCGkTYyswhwF3AtsARYbWZLhqzyGXdfHnxtTmjiONRW6kZAEZmeklYc7r4BaDlnrNHdd4yx6RXAbnd/2d17gfuBVUmKOWGL5xZSkB1RcYjItJOK5zjmA/uHLDcFY6f9nZm9YGZfN7OckT7EzG4zs3ozq29ubk54yEiGcXllVMUhItNOKhbHaD4LXAK8ASgF/nKkFd39bnevc/e6srKypISpqYqy/XAbp3r6k/L5IiKpKBWL4wBQMWR5QTCGux/ymB7ge8QOa4WmtirKoMPmfSfDjCEiMqlSsTieAxaZ2UIzywZuBh4FMLN5wXcD3kPsZHtoLq8swUwnyEVkeknm5bj3Ac8Ci82sycxuNbP3mlkTsAJ4zMzWB+uWm9k6AHfvB24H1gONwAPuvjX42HvN7EXgRWAW8LfJyj8eRblZLJ5TqAc7ici0kpmsD3b31SO89fAw6x4ErhuyvA5YN8x6b09YwASpqYry480HGRx0MjIs7DgiIkmXioeqppTayijtPf3sOnoq7CgiIpNCxXGe9ERAEZluVBznqWpmPjMLslUcIjJtqDjOk5lRUxXVo2RFZNpQcSRAbVWUV451cPxUT9hRRESSTsWRAKfPc2zSjYAiMg2oOBLgdfOLyYqYznOIyLSg4kiA3KwIS8uL2bi3ZeyVRUSmOBVHgtRWRdnS1Epv/2DYUUREkkrFkSB1VVF6+wfZerA17CgiIkml4kiQGt0IKCLThIojQeYU5bIgmqf7OUQk7ak4Eqi2KvZEQHcPO4qISNKoOBKotirKkbYeDpzsCjuKiEjSqDgSqKZS5zlEJP2pOBLokrmF5GdH2KTiEJE0puJIoMxIBssrSvREQBFJayqOBKutitJ4qJ2Onv6wo4iIJIWKI8FqqqIMDDpbmk6GHUVEJClUHAlWUxGcIN+jw1Uikp6SVhxmtsbMjppZw5Cxm8xsq5kNmlndKNuuNLMdZrbbzO4Y5v1/NrOUfMh3cX4WF8+ZofMcIpK2krnHsRZYec5YA3AjsGGkjcwsAtwFXAssAVab2ZIh79cB0USHTaTaqiib9p5gcFA3AopI+klacbj7BqDlnLFGd98xxqZXALvd/WV37wXuB1bBmVL5GvAXSYicMDWVUdq6+3mpOSV3ikREzksqnuOYD+wfstwUjAHcDjzq7ofG+hAzu83M6s2svrm5OQkxR1arCQ9FJI2lYnEMy8zKgZuAb45nfXe/293r3L2urKwsueHOsXBWAdH8LBWHiKSlVCyOA0DFkOUFwdjlwEXAbjPbA+Sb2e7Jjzc2M4tNeKgT5CKShlKxOJ4DFpnZQjPLBm4mdnjqMXef6+7V7l4NdLr7RaEmHUVNVZSXmzto6egNO4qISEIl83Lc+4BngcVm1mRmt5rZe82sCVgBPGZm64N1y81sHYC79xM7l7EeaAQecPetycqZLLXBhIfPa69DRNJMZrI+2N1Xj/DWw8OsexC4bsjyOmDdGJ8/47wCJtmyBSVkZhgb957gmkvnhB1HRCRhUvFQVVrIy46wtLxIJ8hFJO2oOJKopirKlqaT9A0Mhh1FRCRhVBxJVFsVpbtvkG0H28KOIiKSMCqOJNKNgCKSjlQcSTSvOI/5JXm6n0NE0oqKI8lqggkPRUTShYojyWorSzjU2s3Bk11hRxERSQgVR5LVVpUCOs8hIulDxZFkl8wrJC8rouIQkbSh4kiyrEgGr68oZpNOkItImlBxTILaqihbD7bR2dsfdhQRkfOm4pgEtVVRBgadF5paw44iInLeVByT4PIK3QgoIulDxTEJogXZXFhWoPs5RCQtqDgmSV1VKRv3nWBw0MOOIiJyXlQck6S2KsrJzj5ePtYRdhQRkfOi4pgkNcGEhzpcJSJTnYpjklwwq4CS/CydIBeRKU/FMUkyMoyayqhmyhWRKU/FMYlqq6LsPnqKk529YUcREZmwpBWHma0xs6Nm1jBk7CYz22pmg2ZWN8q2K81sh5ntNrM7hoz/m5ltMbMXzOxBM5uRrPzJUFMZO8/x/L6T4QYRETkPydzjWAusPGesAbgR2DDSRmYWAe4CrgWWAKvNbEnw9qfd/fXuvgzYB9ye6NDJ9PqKYiIZpvMcIjKlTbg4zOxPRnvf3TcALeeMNbr7jjE++gpgt7u/7O69wP3AqmD7tuBnG5AHTKmbIvKzM1kyr0jFISJT2vnscfxpwlKcbT6wf8hyUzAGgJl9DzgMXAJ8c6QPMbPbzKzezOqbm5uTFDV+tVVRNu8/Sf/AYNhRREQm5HyKwxKWIg7u/hGgHGgEfneU9e529zp3rysrK5u0fGOpqYrS1TfA9sPtYUcREZmQ8ymOZB0mOgBUDFleEIy9+oPdB4gdwnpfkjIkTV1wI2D9npYx1hQRSU2jFoeZtZtZ2zBf7Qw5fJRgzwGLzGyhmWUDNwOPWsxFQS4DbgC2JylD0pSX5DGvOJeNurJKRKaozNHedPfCiX6wmd0HvBWYZWZNwOeJnSz/JlAGPGZmm939XWZWDnzX3a9z934zux1YD0SANe6+1cwygHvMrIjYYbItwMcnmi9MNVVRTT0iIlPWqMUxGjPb5+6VI73v7qtHeOvhYdY9CFw3ZHkdsO6cdQaBN00sbWqprYzy2AuHONTaxbzivLDjiIjEZcqdHE8HtWcmPDwZbhARkQlIxZPjaW9JeRG5WRm6n0NEpqRRD1WZ2Uj3ahgwpab7SCVZkQyWLSjRhIciMiWNtcdROMLXDOAbyY2W3mqromw90Ep330DYUURE4jLWVVVfnKwg080bF5byrf/3Ej954RDvr10QdhwRkXEb61DV50Z52939SwnOM21cvaiM11eU8NUntrPysrnMyJnwBW4iIpNqrENVHcN8AdwK/GUSc6W9jAzjizcspbm9h28+uSvsOCIi4zZqcbj7/zn9BdxNbEbajxCb7uOCSciX1pZXlPD+2gWsefoVXjnWMfYGIiIpYMzLcc2s1Mz+FniB2KGtGnf/S3c/mvR008BfrFxMTmaEL/1kW9hRRETGZay5qr5GbO6oduB17v4Fd9c1pAk0uzCXT15zEU9uP8pT29XFIpL6xtrj+DNiU5j/NXBw6CSHZtaW/HjTw4evXMgFswr4m59so7dfz+kQkdQ21jmODHfPc/dCdy8a8lXo7kWTFTLdZWdm8L/fvYRXjnXwvV+9EnYcEZFRJfOZ4xKHty2ezTWXzOaff76Lo23dYccRERmRiiOF/PX1S+gdGOSrT4z1WHYRkfCoOFLIwlkF3HrVBfxwUxPPax4rEUlRKo4Uc/vbL2J2YQ5feHQrg4OagFhEUo+KI8XMyMnkjmsvYUtTKz/c1BR2HBGR11BxpKD3LJ9PTWUJX31iB+3dfWHHERE5i4ojBWVkGF+4YSnHO3r45pO7w44jInIWFUeKWraghA/UVrDm6Vd4qflU2HFERM5IWnGY2RozO2pmDUPGbjKzrWY2aGZ1o2y70sx2mNluM7tjyPi9wXhD8PlZycqfCj6zcjF5WRH+5sfbcNeJchFJDcnc41gLrDxnrAG4Edgw0kZmFgHuAq4FlgCrzWxJ8Pa9wCXA64jN1PvRxEZOLbNm5PCpdyziFzubeVLzWIlIikhacbj7BqDlnLFGdx/r7rYrgN3u/rK79xKbwn1VsP06DwC/AdL+0Xm3XFnNhWUFfOkn2+jp12NmRSR8qXiOYz6wf8hyUzB2RnCI6oPAE5OYKxRZkQw+/+6l7DneyZqn94QdR0QkJYtjPP4F2ODuvxxpBTO7zczqzay+ubl5EqMl3tUXl/GOS+dw55O7OKJ5rEQkZKlYHAeAiiHLC4IxAMzs80AZ8KejfYi73+3ude5eV1ZWlpSgk+l/X38pfQPOVx/fHnYUEZnmUrE4ngMWmdlCM8sGbgYeBTCzjwLvAla7+7R6cEXVzAI++uaFPPT8ATbu1TxWIhKeZF6Oex/wLLDYzJrM7FYze6+ZNQErgMfMbH2wbrmZrQNw937gdmA90Ag84O5bg4/9NjAHeNbMNpvZ55KVPxV94m0XMacohy/+WPNYiUh4bDrcH1BXV+f19fVhx0iIHz1/gD/5wWb+4X3L+MAbKsbeQERkgsxso7u/5p67VDxUJaNYtbyc2qoo/7B+O22ax0pEQqDimGLMjC/esJTjHb388892hR1HRKYhFccUdNn8Ym5+QwVrn9nD7qPtYccRkWlGxTFF/fk7F5OXHeGLmsdKRCaZimOKmjkjh0+/42J+uesYP2vUPFYiMnlUHFPYB1dUsWj2DL70k21092keKxGZHCqOKez0PFb7Wjr5t6dfCTuOiEwTKo4p7qpFs3jX0jnc9dRuDrdqHisRST4VRxr4699ZQv+g85XHG8OOIiLTgIojDVSU5vOxqy/gR5sPUr+nZewNRETOg4ojTXz8rRcyrziXL/x4KwOax0pEkkjFkSbyszP57HWX0nCgjQfq94+9gYjIBKk40si7l83jiupSvrZ+B61dmsdKRJJDxZFGzIzP37CEk529/NPPdoYdR0TSlIojzSwtL+bmKyr592f3suuI5rESkcRTcaShP3/nYmbkZHLrPfXsVHmISIKpONJQaUE2az/yBrr6BrjxX57hye1Hwo4kImlExZGmLq+M8sgn3kTVzHxuvaeeuze8pFl0RSQhVBxprLwkj//8oxVce9lc/n7ddj7z4Av09GsyRBE5PyqONJefncmdq2v41DWLeHBjE7//nf/m2KmesGOJyBSm4pgGMjKMT//2xdz5e5fTcLCVVXf+isZDbWHHEpEpKmnFYWZrzOyomTUMGbvJzLaa2aCZ1Y2y7Uoz22Fmu83sjiHjtwdjbmazkpU9XV2/rJz//NiV9A8O8r5vPcN/bT0cdiQRmYKSucexFlh5zlgDcCOwYaSNzCwC3AVcCywBVpvZkuDtXwHvAPYmOux08boFxTx6+1Usmj2Dj31/I3c9tVsnzUUkLkkrDnffALScM9bo7jvG2PQKYLe7v+zuvcD9wKpg++fdfU8y8k4nc4py+cHHVvDuZeV8bf0OPv2DzXqCoIiMWyqe45gPDJ2lrykYi4uZ3WZm9WZW39zcnLBw6SI3K8I3bl7OZ961mB9tPsjv3v1rjrbpQVAiMrZULI6EcPe73b3O3evKysrCjpOSzIxPvO0ivv0Htew83M6qu35Fw4HWsGOJSIpLxeI4AFQMWV4QjEmSrLxsLg9+fAUGvP/bz7DuxUNhRxKRFJaKxfEcsMjMFppZNnAz8GjImdLe0vJiHrn9KpaWF/PH927iGz/bpZPmIjKsZF6Oex/wLLDYzJrM7FYze6+ZNQErgMfMbH2wbrmZrQNw937gdmA90Ag84O5bg/U+GWy/AHjBzL6brPzTUVlhDv/xP97IjTXz+frPdnL7fc/T1auT5iJyNpsOv1XW1dV5fX192DGmDHfnO798mS8/vp3Lyov5zofqmFucG3YsEZlkZrbR3V9zz10qHqqSkJkZt119Id/9UB0vN5/ihjufZvP+k2HHEpEUoeKQEV1z6Rwe+uM3kZOVwQf+9Vke2axrFERExSFjWDy3kEc+cRXLK0r41P2b+cf1OxgcTP/DmyIyMhWHjKm0IJvv3/pGbn5DBXc+tZuP37uRjp7+sGOJSEhUHDIu2ZkZfPnG1/G565fw021HWHXXr3hoU5Oe7yEyDak4ZNzMjD+8aiFrP3IFg+786QNbuPLLT/KP63dwqLUr7HgiMkl0Oa5MiLvz9O5j3PPMXn6+/QgZZrxzyRxuubKaNy4sxczCjigi52mky3EzwwgjU5+Z8eZFZbx5URn7Wzr5/q/3cv9z+3m84TCXzC3kQyuqec/l5eRn66+YSLrRHockTFfvAI9uOcDaZ/bSeKiNwtxMPlBXwYdWVFE1syDseCISp5H2OFQcknDuzsa9J1j7zB6eaDjMgDtvvbiMW66s5upFZWRk6DCWyFSgQ1UyacyMuupS6qpLOdLWzX/89z7+4zf7+PD3nqN6Zj4fXFHNTXULKMrNCjuqiEyA9jhkUvT2D/J4wyH+/dm9bNx7gvzsCO+9fD63XFnNxXMKw44nIsPQoSoVR8poONDKPc/s4ZEtB+ntH2TFBTO55cpq3nHpbDIjukJcJFWoOFQcKaelo5cfPLef7/96LwdOdlFenMvv/1YVq6+opLQgO+x4ItOeikPFkbIGBp2fNx7hnmf38Kvdx8nOzOCqi2bxlovLeMvFZVTP0hVZImHQyXFJWZEM451L5/LOpXPZdaSd+36zn6d2HOXJ7UcBqCzNP1MiKy6cSUGO/tqKhEl7HJKy9h7vYMPOZn6xs5lnXjpOZ+8AWRHjDdWlsSJZXMbiOYW6S10kSXSoSsUxpfX0D7Bxzwl+sauZX+xoZvvhdgDmFOVw9aJYiVx10SxK8nVuRCRRVBwqjrRyuLWbDbtieyO/3NlMW3c/GQbLK0p4y8WzecviMl43v5iIbjYUmTAVh4ojbfUPDLKlqZVfBIe1Xmg6iTuU5Gfx5kWxcyNXXzyL2YV6brpIPCa9OMxsDXA9cNTdLwvGbgK+AFwKXOHuw/7f3MxWAt8AIsB33f0rwfhC4H5gJrAR+KC7946VRcUxvbR09PL07mP8YkesSI6d6gFgybwi3rK4jBUXzGRpeREzZ+SEnFQktYVRHFcDp4B/H1IclwKDwL8Cfz5ccZhZBNgJ/DbQBDwHrHb3bWb2APCQu99vZt8Gtrj7t8bKouKYvgYHncbDbbG9kR3NbNx7gv7g0bdzi3JZUl7E0vIilswrYkl5ERXRfM2lJRKY9Mtx3X2DmVWfM9YYhBlt0yuA3e7+crDu/cAqM2sE3g78XrDePcT2XsYsDpm+MjKMpeXFLC0v5o/fehHt3X282NTKtkNtbD3YxraDsVIZCMqkMCeTS4MSOV0mi+bMICczEvKfRCR1pOIF8fOB/UOWm4A3Ejs8ddLd+4eMzx/pQ8zsNuA2gMrKyuQklSmnMDeLKy+axZUXzToz1t03wM4j7Ww7GJTJoTYeqN9PZ2/ssbiZGcZFs2ewtLz4rEIpztMkjTI9pWJxJIS73w3cDbFDVSHHkRSWmxVh2YISli0oOTM2OOjsOd5x1p7Jhl3N/HBT05l1FkTzWDKv6NVCKS+ivDhX95VI2kvF4jgAVAxZXhCMHQdKzCwz2Os4PS6ScBkZxgVlM7igbAbXLys/M360vZttwV7J1oNtNB5s46eNRzh9qrA4L4vqmflUlMa+KoOvimg+80pyydIkjpIGUrE4ngMWBVdQHQBuBn7P3d3MngLeT+zKqluAR8KLKdPR7MJcZi/O5a2LZ58Z6+jpZ/vhtqBQ2tnf0smLB1p5ouHwmRPxEJtaZV5x7qtlcvormkdlaT6lBdnaW5EpIZlXVd0HvBWYBRwBPg+0AN8EyoCTwGZ3f5eZlRO77Pa6YNvrgH8idjnuGnf/u2D8AmKlUQo8D/yBu/eMlUVXVUkY+gcGOdzWzb6WTva3dLK/pSv2+kRs+dips68kz8+OUFmaz4Lo6T2VvDN7LQui+eRl6wS9TC7dAKjikBTT0dNP04muM8Wyr6WTphOdwXIXXX0DZ61fVphDeUkecwpzmF2Uw5zCXOYU5TK7KIfZhbnMKcohmp+ty4klYTQ7rkiKKcjJZPHcQhbPfe0TEN2dY6d6z+yd7DseK5TDbd3sPd7Jb/a0cLKz7zXbZUUsdjitKIfZhTnMKQrKpTCH2UWxcplTmEtJfpYOi8mEqThEUpCZUVaYQ1lhDjWV0WHX6e4boLm9h6Pt3Rxp6+FIWzdH24PvbT283NzBr19uobXrtQWTHcl4TbmUFeZQNiOHmTOymTkjh5kF2ZQV5pCbpUNkcjYVh8gUlZsVOXOCfTTdfQMcbevhSHusUI60dZ95fbS9m11HT/H07mO0d/cPu31BdoSZM3KYFRTKrBnZzAqKJbb86nsleVk6VDYNqDhE0lxuVoTKmflUzhy9YLp6Bzje0cPxU70cOxV8P2d5f0snz+87SUtHD4PDnB6NZBilBdnMLMg+q1BmzoiNlRbknHm/dEY2hTmZOmQ2Bak4RASAvOwIC7JjV3CNZXDQOdnVx/FTPTQHpXL8VA/HTvVyvCP2/dipHvbt6+T4qR46egeG/ZzsSAbRgixKC3KCYsk+q1jOLZti7dGkBBWHiMQtI9izKC3IZtGc157cP9fpvZmWjl6Od/TScqr31ddDxvef6KTlVC/tPcMfNotkGNH8rCEFEyuVaEE20fwsSvKzKMnPpiQv9j2an0Vhbpaey5JgKg4RSbp49mYg9sTHEx19Z8qmpaOX48OUTePhNlo6eoe9wuw0s9gd/SV5WRQHZXK6WErys4gG34vzXn1dkh87jKa9m+GpOEQk5eRkRphbHGFu8fgevjUw6LR19XGis5eTXX20dgavO/s4GYydDMZaOnp5qfkUJzv7RrwgACAjKJxofjZFeVkU5cXKpSg3k+LTr4PvsfHTY5lpv5ej4hCRKS+SYbHDVQXxPXO+f2CQ1q6+oFh6g3KJvW7terV8Wrv6aO2MXRzQ2hVbHhju6oAhCnMzz5TJ6UIZWjDF+WeXTVHuq0WUk5mR0hcNqDhEZNrKjGQEV33F9zRId6ezd4DWrj7aumN7OG3d/WdKpW3I97bu2Os9x14tnXNnBThXdiTjrDIpCvZ0iobs3ZxbNqffL8rNIjszuZNpqjhEROJkZhTkZFKQk0k5eXFv39s/eKZQYuXSf1bJtHX109b96nutXX00tXSeeb9vYPS9nbysyJliuftDdSycVTDRP+qwVBwiIpMsOzMjuM8l/ufeuzvdfYNDiiVWNK1nXgdl0xlbLshJ/J3/Kg4RkSnEzMjLjpCXHWFO0fguHkg0PVVGRETiouIQEZG4qDhERCQuKg4REYmLikNEROKi4hARkbioOEREJC4qDhERiYu5j37rejows2Zgb9g5hjELOBZ2iAlS9nAoezimavbzzV3l7mXnDk6L4khVZlbv7nVh55gIZQ+HsodjqmZPVm4dqhIRkbioOEREJC4qjnDdHXaA86Ds4VD2cEzV7EnJrXMcIiISF+1xiIhIXFQcIiISFxVHCMyswsyeMrNtZrbVzD4VdqZ4mVnEzJ43s5+EnSUeZlZiZg+a2XYzazSzFWFnGg8z+3Twd6XBzO4zs3Ce4DNOZrbGzI6aWcOQsVIz+6mZ7Qq+R8PMOJwRcn8t+Pvygpk9bGYlIUYc0XDZh7z3Z2bmZjYrET9LxRGOfuDP3H0J8FvAJ8xsSciZ4vUpoDHsEBPwDeAJd78EeD1T4M9gZvOBTwJ17n4ZEAFuDjfVmNYCK88ZuwP4ubsvAn4eLKeatbw290+By9x9GbAT+Oxkhxqntbw2O2ZWAbwT2JeoH6TiCIG7H3L3TcHrdmL/85ofbqrxM7MFwO8A3w07SzzMrBi4Gvg3AHfvdfeToYYav0wgz8wygXzgYMh5RuXuG4CWc4ZXAfcEr+8B3jOZmcZjuNzu/l/u3h8s/hpYMOnBxmGE/+YAXwf+AkjYlVAqjpCZWTVwOfDfIUeJxz8R+4s4GHKOeC0EmoHvBYfZvmtmBWGHGou7HwD+kdhvjIeAVnf/r3BTTcgcdz8UvD4MzAkzzAT9IfB42CHGy8xWAQfcfUsiP1fFESIzmwH8EPgTd28LO894mNn1wFF33xh2lgnIBGqAb7n75UAHqXm45CzBuYBVxIqvHCgwsz8IN9X58dh9AFPqXgAz+ytih5nvDTvLeJhZPvC/gM8l+rNVHCExsyxipXGvuz8Udp44vAm4wcz2APcDbzez74cbadyagCZ3P7139yCxIkl17wBecfdmd+8DHgKuDDnTRBwxs3kAwfejIecZNzP7MHA98Ps+dW5+u5DYLxtbgn+vC4BNZjb3fD9YxRECMzNix9kb3f3/hp0nHu7+WXdf4O7VxE7QPunuU+K3X3c/DOw3s8XB0DXAthAjjdc+4LfMLD/4u3MNU+Ck/jAeBW4JXt8CPBJilnEzs5XEDs3e4O6dYecZL3d/0d1nu3t18O+1CagJ/h2cFxVHON4EfJDYb+ubg6/rwg41TfxP4F4zewFYDvx9uHHGFuwhPQhsAl4k9u82pafAMLP7gGeBxWbWZGa3Al8BftvMdhHbi/pKmBmHM0LuO4FC4KfBv9VvhxpyBCNkT87Pmjp7XSIikgq0xyEiInFRcYiISFxUHCIiEhcVh4iIxEXFISIicckMO4DIdGFmXwBOAUXABnf/WbiJRCZGxSEyydw94VNAiEwmHaoSSSIz+ysz22lmTwOLg7G1Zvb+4PUeM/tycGNZvZnVmNl6M3vJzP4o1PAiI9Aeh0iSmFktsWlZlhP7t7YJGG5yyH3uvtzMvk7smQpvAnKBBiAl71KW6U3FIZI8bwYePj2/kZk9OsJ6p8dfBGYEz2hpN7MeMyuZQs8MkWlCh6pEwtcTfB8c8vr0sn65k5Sj4hBJng3Ae8wsz8wKgXeHHUgkEfTbjEiSuPsmM/sBsIXYsyeeCzmSSEJodlwREYmLDlWJiEhcVBwiIhIXFYeIiMRFxSEiInFRcYiISFxUHCIiEhcVh4iIxOX/A/b/hK04yC83AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dims,losses)\n",
    "plt.xlabel(\"dim\")\n",
    "plt.ylabel(\"NLL\")\n",
    "for i in dims:\n",
    "    print(\"NMI Score dim {} = {}\".format(i,nmi[i-1]))\n",
    "print(\"\\n NLL0 = {}\".format(loss0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
